{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计文章二元词组\n",
    "这篇 文章https://github.com/OpenMindClub/DeepLearningStartUp/blob/master/happiness_seg.txt 中，出现频率最高的前 10 个「二元词组」，并输出它们的频率。「二元词组」即文章中所有接连出现的两个词，如「今天 天气 不错」有「今天 天气」，「天气 不错」两个「二元词组」。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "from __future__ import division\n",
    "import nltk,re,pprint\n",
    "from urllib.request import urlopen\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674947"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从链接地址取得文本\n",
    "url=r'https://raw.githubusercontent.com/OpenMindClub/DeepLearningStartUp/master/happiness_seg.txt'\n",
    "raw = urlopen(url).read()\n",
    "raw = raw.decode('utf-8')\n",
    "# 测试原始文本长度\n",
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n幸福之路\\n第一章 \\u3000 什么 使人 不幸\\n\\n\\n动物 只要 不患 疾病 ， 食物 充足 ， 就 会 快乐 满足 。 人 也 应该 如此 ； 然而 现实 并非 这样 ， 至少 在 大多数 情况 下 并非'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:100] # 取前1000个字符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 由以上文本可知，需要对原始文本进行分割。因为文本已经有空格进行好的分词，因此只需要通过空格分割文本即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '幸福之路',\n",
       " '第一章',\n",
       " '\\u3000',\n",
       " '什么',\n",
       " '使人',\n",
       " '不幸',\n",
       " '',\n",
       " '',\n",
       " '动物',\n",
       " '只要',\n",
       " '不患',\n",
       " '疾病',\n",
       " '，',\n",
       " '食物',\n",
       " '充足',\n",
       " '，',\n",
       " '就',\n",
       " '会',\n",
       " '快乐',\n",
       " '满足',\n",
       " '。',\n",
       " '人',\n",
       " '也']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spl = re.split(r'[ \\t\\n]',raw) # 进行文本切割\n",
    "spl[:25] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面统计出现的二元词组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', ''),\n",
       " ('', '幸福之路'),\n",
       " ('幸福之路', '第一章'),\n",
       " ('第一章', '\\u3000'),\n",
       " ('\\u3000', '什么'),\n",
       " ('什么', '使人'),\n",
       " ('使人', '不幸'),\n",
       " ('不幸', ''),\n",
       " ('', ''),\n",
       " ('', '动物'),\n",
       " ('动物', '只要'),\n",
       " ('只要', '不患'),\n",
       " ('不患', '疾病'),\n",
       " ('疾病', '，'),\n",
       " ('，', '食物'),\n",
       " ('食物', '充足'),\n",
       " ('充足', '，'),\n",
       " ('，', '就'),\n",
       " ('就', '会'),\n",
       " ('会', '快乐'),\n",
       " ('快乐', '满足'),\n",
       " ('满足', '。'),\n",
       " ('。', '人'),\n",
       " ('人', '也')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "list(bigrams(spl[:25])) # 统计出现的二元词组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 但我们会发现，前面有的二元词组包括标点符号，因此还需要清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('的', '人'), 1117),\n",
       " (('他', '的'), 606),\n",
       " (('自己', '的'), 544),\n",
       " (('上', '的'), 474),\n",
       " (('他们', '的'), 416),\n",
       " (('人', '的'), 352),\n",
       " (('的', '时候'), 351),\n",
       " (('的', '孩子'), 293),\n",
       " (('就', '会'), 278),\n",
       " (('的', '东西'), 268)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = '，'\n",
    "w2 = '。'\n",
    "w3 = '―'\n",
    "w4 = '；'\n",
    "w5 = '：'\n",
    "w6 = ''\n",
    "\n",
    "list1 = list(bigrams(spl))\n",
    "listx = list1\n",
    "listn = list1\n",
    "l = len(list1)\n",
    "m = 0\n",
    "\n",
    "for i in range(0,l-1):\n",
    "    c1 = (w1 in listx[i][0]) or (w1 in listx[i][1]) or (w2 in listx[i][0]) or (w2 in listx[i][1])\n",
    "    c2 = (w3 in listx[i][0]) or (w3 in listx[i][1]) or (w4 in listx[i][0]) or (w4 in listx[i][1])\n",
    "    c3 = (w5 in listx[i][0]) or (w5 in listx[i][1]) or (w6 in listx[i][0]) or (w6 in listx[i][1])\n",
    "    if not (c1 or c2):\n",
    "            if listx[i] != ('', ''):\n",
    "                listn[m] = listx[i] \n",
    "                m = m + 1\n",
    "#        del (listx[i])\n",
    "\n",
    "Flist2 = FreqDist(listn)\n",
    "Flist2.most_common(10) # 取前10频率最高词组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
